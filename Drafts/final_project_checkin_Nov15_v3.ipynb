{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project Check-in 2018-11-16\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name\n",
    "-----\n",
    "Data Explorers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Names\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adam Reevesman\n",
    "2. Gokul Krishna\n",
    "3. Hai Le\n",
    "4. Maximillian Alfaro \n",
    "5. Prakhar Agrawal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:49:42.318680Z",
     "start_time": "2018-11-16T12:49:42.308667Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:45:39.522488Z",
     "start_time": "2018-11-16T12:45:18.149377Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakharagrawal/anaconda3/envs/ml/lib/python3.6/site-packages/pandas/io/feather_format.py:112: FutureWarning: `nthreads` argument is deprecated, pass `use_threads` instead\n",
      "  return feather.read_dataframe(path, nthreads=nthreads)\n"
     ]
    }
   ],
   "source": [
    "path = Path('Data/')\n",
    "df = pd.read_feather('Data/May2015_subset.fthr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:52:08.145916Z",
     "start_time": "2018-11-16T11:52:08.124968Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and Feature Engineering\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First to exclude columns that are not helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:45:41.165329Z",
     "start_time": "2018-11-16T12:45:39.525685Z"
    }
   },
   "outputs": [],
   "source": [
    "excluded_var = ['subreddit_id', 'score_hidden', 'author_flair_css_class', \n",
    "                'author_flair_text', 'removal_reason', 'gilded', 'downs', 'archived', \n",
    "                'author', 'retrieved_on', 'edited']\n",
    "df = df.drop(excluded_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:45:45.098016Z",
     "start_time": "2018-11-16T12:45:41.167945Z"
    }
   },
   "outputs": [],
   "source": [
    "df['subreddit'] = df.subreddit.astype('category')\n",
    "# fill na in `distinguised` with 0\n",
    "df['distinguished'].fillna('None', inplace=True)\n",
    "df['distinguished'] = df.distinguished.astype('category')\n",
    "df['link_id'] = df.link_id.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make sure the data is in the format we want, eg. for time data to be in datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:45:45.208298Z",
     "start_time": "2018-11-16T12:45:45.101542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert into date-time type\n",
    "df['time'] = pd.to_datetime(df.created_utc, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers: the target variable we want to predict is the `score` of the comment. By checking the distribution plot of this variable, we've identified that most comments have scores in the range from -20 to 20. There are, however, a number of comments that scored as high as almost 6000. To avoid noise, we will remove comments that scored below -20 and above 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:45:46.131128Z",
     "start_time": "2018-11-16T12:45:45.212015Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[(df['score'] <= 20) & (df['score'] >= -20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create features based on the raw data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:46:40.502381Z",
     "start_time": "2018-11-16T12:45:46.133729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the time lapse of each comment compared with the first one\n",
    "df_first_comment = df[['link_id', 'time']].groupby(by=['link_id']).min()\n",
    "df_first_comment_dict = df_first_comment.to_dict('index')\n",
    "\n",
    "def time_zero(x):\n",
    "    return df_first_comment_dict[x]['time']\n",
    "\n",
    "df['time_lapse'] = df.time - df.link_id.apply(time_zero)\n",
    "\n",
    "df['time_lapse'] = df.time_lapse.apply(lambda x: x.seconds)  # convert into seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:46:52.917346Z",
     "start_time": "2018-11-16T12:46:40.504229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the depth of the comment in the thread\n",
    "def pd_to_dict(df, index='', column=''):\n",
    "    dft = df.copy(deep=True)\n",
    "    dft.index = dft[index]\n",
    "    dft = dft.drop([index], axis=1)\n",
    "    res = dft.to_dict()[column]\n",
    "    del dft\n",
    "    return res\n",
    "\n",
    "comment_to_parent_dict = pd_to_dict(df[['name', 'parent_id']],\n",
    "                                    index='name', column='parent_id')\n",
    "\n",
    "def get_depth(x):\n",
    "    counter = 0\n",
    "    temp = x\n",
    "    while True:\n",
    "        if temp[:3] == 't3_':\n",
    "            return counter\n",
    "        try:\n",
    "            temp = comment_to_parent_dict[temp]\n",
    "        except KeyError:\n",
    "            return np.nan\n",
    "        counter += 1\n",
    "        \n",
    "df['depth'] = df['name'].apply(get_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fraction of records doesn't have a proper `parent_id` which results in nulls in our derived feature `depth`. So we will remove those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:46:53.716442Z",
     "start_time": "2018-11-16T12:46:52.919059Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df.depth.isna() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also get rid of unuseful records, ie. those whose comment text was deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:46:54.612158Z",
     "start_time": "2018-11-16T12:46:53.718087Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[~(df.body == '[deleted]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:46:56.790584Z",
     "start_time": "2018-11-16T12:46:54.615116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comment types: response to other comments or to links\n",
    "df['respond_to_comment']=np.where(df['parent_id'].str.startswith('t1'), 1,0)\n",
    "df['respond_to_link']=np.where(df['parent_id'].str.startswith('t3'),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:46:59.374171Z",
     "start_time": "2018-11-16T12:46:56.792786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subjectivity of the comments\n",
    "df['subjectivity'] = df['body'].str.count('i ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:47:38.234162Z",
     "start_time": "2018-11-16T12:46:59.376901Z"
    }
   },
   "outputs": [],
   "source": [
    "# word count \n",
    "df['body'] = df['body'].str.replace('[.,?!;:]', '')  # remove punctuations\n",
    "df['word_count'] = df['body'].str.split().str.len()\n",
    "\n",
    "# remove comments that have  more than 300 words (outliers)\n",
    "df = df[df['word_count'] < 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:47:44.622653Z",
     "start_time": "2018-11-16T12:47:38.239365Z"
    }
   },
   "outputs": [],
   "source": [
    "# word count categorical variable\n",
    "bins=[-1, 25, 50, 100, 300]\n",
    "df['word_count_cat'] = pd.cut(df['word_count'], \n",
    "                                  bins, labels=['short', 'medium', 'long', 'very long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:47:49.886890Z",
     "start_time": "2018-11-16T12:47:44.630097Z"
    }
   },
   "outputs": [],
   "source": [
    "df['linked_sr'] = df.body.apply(lambda x: re.findall(r\"/r/([^\\s/]+)\", x))\n",
    "df['no_of_linked_sr'] = df['linked_sr'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:47:50.104605Z",
     "start_time": "2018-11-16T12:47:49.900899Z"
    }
   },
   "outputs": [],
   "source": [
    "df['weekday'] = df['time'].dt.dayofweek\n",
    "df['weekday'] = df.weekday.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scikit-learn model\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the features we want, we can drop original features that are no longer needed for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:47:50.112523Z",
     "start_time": "2018-11-16T12:47:50.106912Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_variables = ['created_utc', 'ups', 'link_id', 'name', 'id',\n",
    "       'parent_id', 'time', 'linked_sr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:47:51.823646Z",
     "start_time": "2018-11-16T12:47:50.114928Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(drop_variables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:54:16.470384Z",
     "start_time": "2018-11-16T11:54:16.455061Z"
    }
   },
   "outputs": [],
   "source": [
    "df.tail(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numeric predictors:**\n",
    "\n",
    "`ups`, `time_lapse`, `depth`, `subjectivity`, `word_count`, `no_of_linked_sr` \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical predictors:**\n",
    "* Those that do not need encoding: `controversiality`, `respond_to_comment`, `respond_to_link`\n",
    "* Those that do: `weekday`, `word_count_cat`, `subreddit`, `distinguished`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text-based data:** `body` which is the text of the comment. We will encode it using a Tf-idf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:52:46.206191Z",
     "start_time": "2018-11-16T12:52:43.947512Z"
    }
   },
   "outputs": [],
   "source": [
    "cate_variables = ['weekday', 'word_count_cat', 'subreddit', 'distinguished']\n",
    "X_non_text = pd.get_dummies(df, columns=cate_variables).drop(['body', 'score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:54:21.691704Z",
     "start_time": "2018-11-16T12:52:46.209779Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:54:28.527015Z",
     "start_time": "2018-11-16T12:54:21.693521Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y = df['score'].values\n",
    "X = hstack([X_tfidf, X_non_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:54:28.541101Z",
     "start_time": "2018-11-16T12:54:28.535728Z"
    }
   },
   "outputs": [],
   "source": [
    "assert X.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:54:39.806990Z",
     "start_time": "2018-11-16T12:54:28.558674Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                    random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:55:38.259304Z",
     "start_time": "2018-11-16T12:54:39.809664Z"
    }
   },
   "outputs": [],
   "source": [
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X_train, y_train)\n",
    "y_predicted = lm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:57:02.188487Z",
     "start_time": "2018-11-16T11:57:02.179452Z"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_predicted)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:57:02.205483Z",
     "start_time": "2018-11-16T11:57:02.191433Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_pred=y_predicted, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:55:38.272119Z",
     "start_time": "2018-11-16T12:55:38.261001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0599\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_predicted)\n",
    "print(f\"{r2:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:57:03.283092Z",
     "start_time": "2018-11-16T11:57:02.226075Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "\n",
    "sns.distplot(y_test, ax=ax0)\n",
    "ax0.set(xlabel='Test scores', xlim=(-20,20))\n",
    "\n",
    "sns.distplot(y_predicted, ax=ax1)\n",
    "ax1.set(xlabel=\"Predicted scores\", xlim=(-20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T13:33:20.232398Z",
     "start_time": "2018-11-16T12:56:13.029237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06064\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeRegressor(max_depth=15)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_predicted = dt_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "print(f\"{r2:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:57:03.291346Z",
     "start_time": "2018-11-16T11:57:03.285366Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# All entries with score_hidden = 1, have the same score, i.e, 1\n",
    "print(df[df['score_hidden']==0][\"score\"].unique())\n",
    "print(df[df['score_hidden']==1][\"score\"].unique())\n",
    "\n",
    "# Removing rows with hidden scores from the model.\n",
    "df = df[df['score_hidden'] == 0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:57:03.307733Z",
     "start_time": "2018-11-16T11:57:03.301178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scores are very high for gilded!= 0 posts, compared to gilded = 0 ones. Same is the case for the variable edited.\n",
    "# Whether author has flair or not, however, does not affect \n",
    "\n",
    "\"\"\"\n",
    "print(np.mean(df[df[\"gilded\"] != 0][\"score\"]))\n",
    "print(np.mean(df[df[\"gilded\"] == 0][\"score\"]))\n",
    "print(\"\")\n",
    "\n",
    "df[\"author_has_flair\"] = df[\"author_flair_text\"].apply(lambda x: int(x is not None))\n",
    "print(np.mean(df[df[\"author_has_flair\"] != 0][\"score\"]))\n",
    "print(np.mean(df[df[\"author_has_flair\"] == 0][\"score\"]))\n",
    "print(\"\")\n",
    "\n",
    "print(np.mean(df[df[\"edited\"] != 0][\"score\"]))\n",
    "print(np.mean(df[df[\"edited\"] == 0][\"score\"]))\n",
    "\n",
    "df[\"non_zero_guild\"] = df[\"gilded\"].apply(lambda x: int(x !=0))\n",
    "df[\"edit_flag\"] = df[\"edited\"].apply(lambda x: int(x !=0))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T11:57:03.298809Z",
     "start_time": "2018-11-16T11:57:03.293725Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "comment_to_score_dict = pd_to_dict(df[['name', 'score']],\n",
    "                                    index='name', column='score')\n",
    "def get_parent_score(name):\n",
    "    try:\n",
    "        x = comment_to_score_dict[comment_to_parent_dict[name]]\n",
    "        return x\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "df[\"parent_scores\"] = df['name'].apply(get_parent_score)\n",
    "\n",
    "df = df[df[\"parent_scores\"].isna() == False]\n",
    "\n",
    "len(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:22:42.823153Z",
     "start_time": "2018-11-16T12:22:42.792601Z"
    }
   },
   "outputs": [],
   "source": [
    "subreddit_counts = df[\"subreddit\"].value_counts().to_dict()\n",
    "mse_list = []\n",
    "r2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:32:35.382173Z",
     "start_time": "2018-11-16T12:30:17.920874Z"
    }
   },
   "outputs": [],
   "source": [
    "for sr in subreddit_counts.keys():\n",
    "    df2 = df[df[\"subreddit\"]==sr]\n",
    "    \n",
    "    cate_variables = ['weekday', 'word_count_cat', 'subreddit', 'distinguished']\n",
    "    X_non_text = pd.get_dummies(df2, columns=cate_variables).drop(['body', 'score'], axis=1)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_tfidf = vectorizer.fit_transform(df2['body'])\n",
    "    \n",
    "    Y = df2['score'].values\n",
    "    X = hstack([X_tfidf, X_non_text])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                    random_state=3)\n",
    "    lm_model = LinearRegression()\n",
    "    lm_model.fit(X_train, y_train)\n",
    "    y_predicted = lm_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_predicted)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "    r2 = r2_score(y_test, y_predicted)\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T12:32:35.665022Z",
     "start_time": "2018-11-16T12:32:35.661800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Was thinking of aggregating r2_list and mse_list, but apparently, the predictions are so bad that it's not worth it\n",
    "# Got me thinking, though, that the ensemble method tried above, could be tried for features that weren't\n",
    "# performing very well in the model. Maybe that will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
